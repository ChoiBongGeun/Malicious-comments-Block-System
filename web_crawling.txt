//html 전체 크롤링 requests는 http 요청을 보낼때 beautifulsoup는 html 에서 정보를 가져오기 위해 사용하는 라이브러리
import pandas as pd
test_url = "https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=136900&type=after&page=1"
resp = requests.get(test_url)
html = BeautifulSoup(resp.content, 'html.parser')
html
//댓글전체 부분
score_result = html.find('div', {'class': 'score_result'})
lis = score_result.findAll('li')
lis[0]
//댓글 내용
review_text = lis[0].find('p').getText()
review_text
//좋아요 싫어요 
like = lis[0].find('div', {'class': 'btn_area'}).findAll('span')[1].getText()
dislike = lis[0].find('div', {'class': 'btn_area'}).findAll('span')[3].getText()
like, dislike
//닉네임 
nickname = lis[0].findAll('a')[0].find('span').getText()
nickname
//작성일
from datetime import datetime
created_at = datetime.strptime(lis[0].find('dt').findAll('em')[-1].getText(), "%Y.%m.%d %H:%M")
created_at
//results 배열에 저장
results =[]
def get_data(url):
    resp = requests.get(url)
    html = BeautifulSoup(resp.content, 'html.parser')
    score_result = html.find('div', {'class': 'score_result'})
    lis = score_result.findAll('li')
    for li in lis:        
        nickname = li.findAll('a')[0].find('span').getText()
        created_at = datetime.strptime(li.find('dt').findAll('em')[-1].getText(), "%Y.%m.%d %H:%M")
        
        review_text = li.find('p').getText()
        score = li.find('em').getText()
        btn_likes = li.find('div', {'class': 'btn_area'}).findAll('span')
        like = btn_likes[1].getText()
        dislike = btn_likes[3].getText()
        results.append([nickname, review_text, score, like, dislike, created_at])
//댓글 전체수 보기
result = html.find('div', {'class':'score_total'}).find('strong').findChildren('em')[1].getText()
int(result.replace(',', ''))
//댓글 전체 가져오기
test_url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=136900&type=after'
resp = requests.get(test_url)
html = BeautifulSoup(resp.content, 'html.parser')
result = html.find('div', {'class':'score_total'}).find('strong').findChildren('em')[1].getText()
total_count = int(result.replace(',', ''))

for i in range(1, int(total_count / 10) + 1):
    url = test_url + '&page=' + str(i)
    print('url: "' + url + '')
    get_data(url)
data = pd.DataFrame(results)
data.columns = ['nickname', 'review', 'score', 'like', 'dislike', 'created_date']
data.to_csv('C:\\Users\\dhy00\\Desktop\\결과값.csv', encoding='cp949')